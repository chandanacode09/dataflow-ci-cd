# Auto-generated CD configuration for austin-311-pipeline-1
# This file defines the continuous deployment workflow for streaming pipeline

steps:
  # Install dependencies
  - name: 'python:3.9'
    id: 'install-dependencies'
    entrypoint: bash
    args:
      - '-c'
      - |
        cd pipelines/austin-311-pipeline-1
        pip install -r requirements.txt

  # Deploy streaming pipeline to Dataflow
  - name: 'python:3.9'
    id: 'deploy-dataflow-streaming'
    entrypoint: bash
    args:
      - '-c'
      - |
        cd pipelines/austin-311-pipeline-1

        echo "Deploying austin-311-pipeline-1 streaming pipeline to Dataflow..."

        python main.py \
          --runner DataflowRunner \
          --project axiomatic-robot-458302-r0 \
          --region us-central1 \
          --temp_location gs://axiomatic-robot-458302-r0-dataflow-temp/austin-311-pipeline-1/ \
          --staging_location gs://axiomatic-robot-458302-r0-dataflow-staging/austin-311-pipeline-1/ \
          --input_table axiomatic-robot-458302-r0:austin_311.311_service_requests \
          --output_table axiomatic-robot-458302-r0:austin_311.processed_311_requests \
          --window_duration 60 \
          --job_name austin-311-pipeline-1-${SHORT_SHA} \
--max_num_workers 4 \--machine_type n1-standard-2 \--disk_size_gb 50 \          --service_account_email dataflow-sa@axiomatic-robot-458302-r0.iam.gserviceaccount.com \
          --streaming \
          --enable_streaming_engine \
          --setup_file ./setup.py

# Service account with Dataflow permissions
serviceAccount: 'dataflow-sa@axiomatic-robot-458302-r0.iam.gserviceaccount.com'

# Timeout (streaming deployments can take longer)
timeout: '1800s'

# Options
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'N1_HIGHCPU_8'

# Substitutions (provided by trigger)
substitutions:
  _DATASET_ID: 'austin_311'
  _SOURCE_TABLE: '311_service_requests'
  _DEST_TABLE: 'processed_311_requests'
  _WINDOW_DURATION: '60'